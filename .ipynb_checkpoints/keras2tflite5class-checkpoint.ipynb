{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "def save_graph_to_file(sess,  graph_file_name, output_names):\n",
    "    output_graph_def = graph_util.convert_variables_to_constants(\n",
    "      sess,  sess.graph.as_graph_def(),  output_names)\n",
    "    with gfile.FastGFile(graph_file_name, 'wb') as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "def keras2tflite(sess, input_tensors, output_tensors, filename):\n",
    "    '''\n",
    "    input_tensor and output_tensors is array and is keras input and output tensor\n",
    "    filename must be .tflite\n",
    "    '''\n",
    "    converter = tf.contrib.lite.TocoConverter.from_session(sess, input_tensors, output_tensors)\n",
    "    tflite_model=converter.convert()\n",
    "    open(filename, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Epoch 1/50\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 1.5979 - acc: 0.2636 - val_loss: 1.5069 - val_acc: 0.3906\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 1.4282 - acc: 0.3479 - val_loss: 1.1422 - val_acc: 0.4531\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 10s 126ms/step - loss: 1.2415 - acc: 0.4654 - val_loss: 1.2350 - val_acc: 0.5156\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 10s 126ms/step - loss: 1.1889 - acc: 0.4684 - val_loss: 1.0782 - val_acc: 0.5312\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 1.2044 - acc: 0.4955 - val_loss: 1.1707 - val_acc: 0.4531\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 1.1304 - acc: 0.5301 - val_loss: 0.9153 - val_acc: 0.6250\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 1.0927 - acc: 0.5663 - val_loss: 1.0445 - val_acc: 0.5625\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 1.0778 - acc: 0.5587 - val_loss: 0.9707 - val_acc: 0.6562\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 1.0460 - acc: 0.5906 - val_loss: 0.7856 - val_acc: 0.6094\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 10s 117ms/step - loss: 1.0153 - acc: 0.6032 - val_loss: 0.9416 - val_acc: 0.5938\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.9785 - acc: 0.6310 - val_loss: 1.0879 - val_acc: 0.6094\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - 10s 118ms/step - loss: 0.9262 - acc: 0.6421 - val_loss: 0.9083 - val_acc: 0.7344\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.9269 - acc: 0.6393 - val_loss: 0.8879 - val_acc: 0.6250\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.8847 - acc: 0.6566 - val_loss: 0.7922 - val_acc: 0.7031\n",
      "Epoch 15/50\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.8658 - acc: 0.6732 - val_loss: 0.8607 - val_acc: 0.6250\n",
      "Epoch 16/50\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.8648 - acc: 0.6672 - val_loss: 0.8285 - val_acc: 0.7344\n",
      "Epoch 17/50\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.8327 - acc: 0.6832 - val_loss: 0.5867 - val_acc: 0.7656\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.8218 - acc: 0.6792 - val_loss: 1.0213 - val_acc: 0.6562\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 0.8324 - acc: 0.6883 - val_loss: 0.7172 - val_acc: 0.7656\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.8082 - acc: 0.7058 - val_loss: 0.8139 - val_acc: 0.7031\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - 11s 128ms/step - loss: 0.8196 - acc: 0.6837 - val_loss: 0.7039 - val_acc: 0.7500\n",
      "Epoch 22/50\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 0.7173 - acc: 0.7297 - val_loss: 0.8571 - val_acc: 0.6094\n",
      "Epoch 23/50\n",
      "83/83 [==============================] - 10s 117ms/step - loss: 0.7389 - acc: 0.7191 - val_loss: 0.7757 - val_acc: 0.7812\n",
      "Epoch 24/50\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.7981 - acc: 0.7026 - val_loss: 0.5743 - val_acc: 0.7344\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 0.7714 - acc: 0.7146 - val_loss: 0.6633 - val_acc: 0.7031\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.7359 - acc: 0.7093 - val_loss: 0.7156 - val_acc: 0.7344\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.7436 - acc: 0.7206 - val_loss: 0.7779 - val_acc: 0.6719\n",
      "Epoch 28/50\n",
      "83/83 [==============================] - 10s 116ms/step - loss: 0.7354 - acc: 0.7269 - val_loss: 0.7441 - val_acc: 0.7500\n",
      "Epoch 29/50\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 0.7070 - acc: 0.7282 - val_loss: 0.5971 - val_acc: 0.7812\n",
      "Epoch 30/50\n",
      "83/83 [==============================] - 10s 118ms/step - loss: 0.7244 - acc: 0.7214 - val_loss: 0.5898 - val_acc: 0.7656\n",
      "Epoch 31/50\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.7266 - acc: 0.7292 - val_loss: 0.6530 - val_acc: 0.7812\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 0.6873 - acc: 0.7462 - val_loss: 0.6277 - val_acc: 0.8125\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 0.6699 - acc: 0.7462 - val_loss: 0.5285 - val_acc: 0.7812\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.6895 - acc: 0.7397 - val_loss: 0.7682 - val_acc: 0.6875\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.6521 - acc: 0.7530 - val_loss: 0.7575 - val_acc: 0.7188\n",
      "Epoch 36/50\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.6843 - acc: 0.7455 - val_loss: 0.5143 - val_acc: 0.8281\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.6614 - acc: 0.7510 - val_loss: 0.6265 - val_acc: 0.7344\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 0.6405 - acc: 0.7598 - val_loss: 0.4628 - val_acc: 0.8281\n",
      "Epoch 39/50\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.6980 - acc: 0.7485 - val_loss: 0.8651 - val_acc: 0.6719\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 0.6212 - acc: 0.7636 - val_loss: 0.7737 - val_acc: 0.7344\n",
      "Epoch 41/50\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.6277 - acc: 0.7688 - val_loss: 0.4690 - val_acc: 0.8281\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.6213 - acc: 0.7743 - val_loss: 0.3072 - val_acc: 0.8906\n",
      "Epoch 43/50\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.5883 - acc: 0.7877 - val_loss: 0.5357 - val_acc: 0.7656\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - 10s 118ms/step - loss: 0.6518 - acc: 0.7402 - val_loss: 0.5493 - val_acc: 0.7812\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.6208 - acc: 0.7781 - val_loss: 0.5165 - val_acc: 0.8125\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.5850 - acc: 0.7801 - val_loss: 0.4404 - val_acc: 0.8281\n",
      "Epoch 47/50\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.6021 - acc: 0.7839 - val_loss: 0.6057 - val_acc: 0.8125\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - 10s 118ms/step - loss: 0.5752 - acc: 0.7736 - val_loss: 0.6547 - val_acc: 0.7344\n",
      "Epoch 49/50\n",
      "83/83 [==============================] - 11s 129ms/step - loss: 0.5964 - acc: 0.7771 - val_loss: 0.5151 - val_acc: 0.8125\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - 10s 117ms/step - loss: 0.6175 - acc: 0.7618 - val_loss: 0.4762 - val_acc: 0.8594\n",
      "INFO:tensorflow:Froze 18 variables.\n",
      "INFO:tensorflow:Converted 18 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os\n",
    "from keras import optimizers\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "train_path='/home/sober/code/jupyter/ftp_code/AndroidTensorflow/tensorflow-for-poets-2/tf_files/flower_photos'\n",
    "val_path='/home/sober/code/jupyter/ftp_code/AndroidTensorflow/tensorflow-for-poets-2/tf_files/flower_photos'\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "def mean(x):\n",
    "    return (x-128.0)\n",
    "\n",
    "input = Input(shape = (150, 150, 3), name = 'input')\n",
    "x = Conv2D(32, (3, 3), activation='relu')(input)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dense(2, activation='sigmoid', name = 'output')(x)\n",
    "x = Dense(5, activation='softmax', name = 'output')(x)\n",
    "model = Model(inputs = input, outputs= x)\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True, preprocessing_function=mean)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=mean)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1340 // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        shuffle=True,\n",
    "        validation_steps=64 // batch_size)\n",
    "model.save('./weight/flower5tlite_mean.h5')  # always save your weights after training or during training\n",
    "\n",
    "# convert\n",
    "output_names = [node.op.name for node in model.outputs]\n",
    "\n",
    "export_dir = './weight/'\n",
    "sess = K.get_session()\n",
    "# save_graph_to_file(sess,  export_dir + \"flower5.pb\", output_names)\n",
    "keras2tflite(sess, [input], [x], export_dir + \"flower5tlite.tflite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.2",
   "language": "python",
   "name": "3.6.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
