{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "def save_graph_to_file(sess,  graph_file_name, output_names):\n",
    "    output_graph_def = graph_util.convert_variables_to_constants(\n",
    "      sess,  sess.graph.as_graph_def(),  output_names)\n",
    "    with gfile.FastGFile(graph_file_name, 'wb') as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "def keras2tflite(sess, input_tensors, output_tensors, filename):\n",
    "    '''\n",
    "    input_tensor and output_tensors is array and is keras input and output tensor\n",
    "    filename must be .tflite\n",
    "    '''\n",
    "    converter = tf.contrib.lite.TocoConverter.from_session(sess, input_tensors, output_tensors)\n",
    "    tflite_model=converter.convert()\n",
    "    open(filename, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n",
      "Found 3670 images belonging to 5 classes.\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 10s 126ms/step - loss: 1.5463 - acc: 0.3313 - val_loss: 1.2532 - val_acc: 0.3750\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 1.2651 - acc: 0.4511 - val_loss: 1.4297 - val_acc: 0.3750\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 1.2330 - acc: 0.4659 - val_loss: 1.2457 - val_acc: 0.4844\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 11s 127ms/step - loss: 1.1470 - acc: 0.5113 - val_loss: 1.2128 - val_acc: 0.4219\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 1.1165 - acc: 0.5233 - val_loss: 0.9825 - val_acc: 0.5781\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 10s 117ms/step - loss: 1.1084 - acc: 0.5524 - val_loss: 1.1478 - val_acc: 0.5312\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 1.0826 - acc: 0.5512 - val_loss: 1.1038 - val_acc: 0.5625\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 1.0095 - acc: 0.5911 - val_loss: 1.1058 - val_acc: 0.6406\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 1.0112 - acc: 0.6090 - val_loss: 0.7448 - val_acc: 0.7500\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 1.0327 - acc: 0.5904 - val_loss: 1.0543 - val_acc: 0.5469\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.9961 - acc: 0.6160 - val_loss: 1.0370 - val_acc: 0.6094\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 0.9211 - acc: 0.6506 - val_loss: 0.8637 - val_acc: 0.6719\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.9861 - acc: 0.6084 - val_loss: 0.9837 - val_acc: 0.6406\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 11s 128ms/step - loss: 0.9018 - acc: 0.6649 - val_loss: 0.9029 - val_acc: 0.6562\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.9212 - acc: 0.6574 - val_loss: 0.8040 - val_acc: 0.6094\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 11s 127ms/step - loss: 0.8572 - acc: 0.6657 - val_loss: 0.7751 - val_acc: 0.7031\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.8891 - acc: 0.6479 - val_loss: 0.7546 - val_acc: 0.7188\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.8773 - acc: 0.6619 - val_loss: 0.8171 - val_acc: 0.6250\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.8402 - acc: 0.6800 - val_loss: 0.8475 - val_acc: 0.7188\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 10s 118ms/step - loss: 0.7918 - acc: 0.6988 - val_loss: 0.6649 - val_acc: 0.7500\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.8427 - acc: 0.6845 - val_loss: 0.6833 - val_acc: 0.7656\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.8061 - acc: 0.6965 - val_loss: 0.6841 - val_acc: 0.7812\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 10s 118ms/step - loss: 0.8335 - acc: 0.6770 - val_loss: 0.8144 - val_acc: 0.7344\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.7786 - acc: 0.7026 - val_loss: 0.8071 - val_acc: 0.6719\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 10s 118ms/step - loss: 0.7703 - acc: 0.7231 - val_loss: 0.7524 - val_acc: 0.6250\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.8135 - acc: 0.6867 - val_loss: 0.6052 - val_acc: 0.7812\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 0.7514 - acc: 0.7154 - val_loss: 0.7885 - val_acc: 0.7344\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 10s 126ms/step - loss: 0.6985 - acc: 0.7329 - val_loss: 0.8416 - val_acc: 0.6406\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.6815 - acc: 0.7492 - val_loss: 0.6993 - val_acc: 0.6875\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.7706 - acc: 0.7063 - val_loss: 0.6725 - val_acc: 0.7344\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.7416 - acc: 0.7221 - val_loss: 0.8681 - val_acc: 0.6562\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.7083 - acc: 0.7357 - val_loss: 0.7203 - val_acc: 0.7969\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.7359 - acc: 0.7252 - val_loss: 0.6737 - val_acc: 0.7188\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 11s 128ms/step - loss: 0.6974 - acc: 0.7430 - val_loss: 0.7230 - val_acc: 0.7188\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.6895 - acc: 0.7455 - val_loss: 0.6188 - val_acc: 0.7656\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.7043 - acc: 0.7297 - val_loss: 0.4120 - val_acc: 0.8594\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.6646 - acc: 0.7415 - val_loss: 0.5210 - val_acc: 0.8125\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.7006 - acc: 0.7349 - val_loss: 0.7049 - val_acc: 0.7344\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 0.6462 - acc: 0.7533 - val_loss: 0.8418 - val_acc: 0.6562\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.6563 - acc: 0.7530 - val_loss: 0.5995 - val_acc: 0.7812\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 11s 127ms/step - loss: 0.6998 - acc: 0.7387 - val_loss: 0.6374 - val_acc: 0.7500\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.6773 - acc: 0.7375 - val_loss: 0.4185 - val_acc: 0.8594\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.6706 - acc: 0.7530 - val_loss: 0.5879 - val_acc: 0.7344\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 11s 130ms/step - loss: 0.6250 - acc: 0.7636 - val_loss: 0.4076 - val_acc: 0.8750\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 10s 116ms/step - loss: 0.6373 - acc: 0.7598 - val_loss: 0.6409 - val_acc: 0.7188\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.6767 - acc: 0.7440 - val_loss: 0.6362 - val_acc: 0.7500\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 11s 131ms/step - loss: 0.6392 - acc: 0.7613 - val_loss: 0.5550 - val_acc: 0.8125\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.6462 - acc: 0.7608 - val_loss: 0.6292 - val_acc: 0.7969\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 11s 128ms/step - loss: 0.5851 - acc: 0.7846 - val_loss: 0.5520 - val_acc: 0.8125\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.5997 - acc: 0.7633 - val_loss: 0.5155 - val_acc: 0.8125\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.6022 - acc: 0.7779 - val_loss: 0.6088 - val_acc: 0.7188\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.6081 - acc: 0.7877 - val_loss: 0.5136 - val_acc: 0.8438\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.5864 - acc: 0.7726 - val_loss: 0.5270 - val_acc: 0.7812\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.5518 - acc: 0.7839 - val_loss: 0.4096 - val_acc: 0.8750\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 10s 126ms/step - loss: 0.5666 - acc: 0.7892 - val_loss: 0.5002 - val_acc: 0.8281\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 0.5692 - acc: 0.7864 - val_loss: 0.6611 - val_acc: 0.7500\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.5235 - acc: 0.8005 - val_loss: 0.3078 - val_acc: 0.8750\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.5731 - acc: 0.7937 - val_loss: 0.2864 - val_acc: 0.8889\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 0.5451 - acc: 0.7997 - val_loss: 0.3530 - val_acc: 0.9062\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.4983 - acc: 0.8230 - val_loss: 0.4996 - val_acc: 0.8125\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 10s 117ms/step - loss: 0.5352 - acc: 0.8062 - val_loss: 0.4720 - val_acc: 0.8125\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 10s 118ms/step - loss: 0.5115 - acc: 0.8117 - val_loss: 0.4345 - val_acc: 0.8750\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.5489 - acc: 0.7967 - val_loss: 0.3844 - val_acc: 0.8594\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.5308 - acc: 0.7999 - val_loss: 0.2737 - val_acc: 0.9219\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 10s 126ms/step - loss: 0.5180 - acc: 0.8050 - val_loss: 0.4563 - val_acc: 0.8281\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.5073 - acc: 0.8050 - val_loss: 0.4615 - val_acc: 0.7969\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 10s 116ms/step - loss: 0.5196 - acc: 0.8042 - val_loss: 0.4303 - val_acc: 0.8750\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 10s 126ms/step - loss: 0.4955 - acc: 0.8133 - val_loss: 0.3011 - val_acc: 0.8750\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 10s 118ms/step - loss: 0.5261 - acc: 0.7944 - val_loss: 0.4517 - val_acc: 0.8125\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.5351 - acc: 0.8007 - val_loss: 0.4171 - val_acc: 0.8594\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.4516 - acc: 0.8276 - val_loss: 0.4308 - val_acc: 0.8750\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.4694 - acc: 0.8230 - val_loss: 0.4688 - val_acc: 0.7500\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 11s 127ms/step - loss: 0.4950 - acc: 0.8210 - val_loss: 0.5334 - val_acc: 0.8125\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.4711 - acc: 0.8276 - val_loss: 0.2510 - val_acc: 0.9062\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 10s 116ms/step - loss: 0.4757 - acc: 0.8240 - val_loss: 0.2582 - val_acc: 0.9062\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.4309 - acc: 0.8343 - val_loss: 0.4660 - val_acc: 0.8438\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 11s 128ms/step - loss: 0.4792 - acc: 0.8223 - val_loss: 0.4197 - val_acc: 0.8281\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.4349 - acc: 0.8303 - val_loss: 0.4901 - val_acc: 0.8438\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.4416 - acc: 0.8351 - val_loss: 0.5150 - val_acc: 0.8125\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.4543 - acc: 0.8313 - val_loss: 0.2522 - val_acc: 0.9219\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.4554 - acc: 0.8296 - val_loss: 0.3098 - val_acc: 0.8594\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 10s 116ms/step - loss: 0.4296 - acc: 0.8389 - val_loss: 0.3318 - val_acc: 0.8594\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.4200 - acc: 0.8449 - val_loss: 0.3144 - val_acc: 0.8906\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.3912 - acc: 0.8484 - val_loss: 0.2656 - val_acc: 0.8750\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 10s 125ms/step - loss: 0.4545 - acc: 0.8441 - val_loss: 0.3106 - val_acc: 0.8594\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.4276 - acc: 0.8512 - val_loss: 0.2438 - val_acc: 0.9062\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 0.4367 - acc: 0.8411 - val_loss: 0.2460 - val_acc: 0.9219\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 0.4443 - acc: 0.8404 - val_loss: 0.3723 - val_acc: 0.8125\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 10s 122ms/step - loss: 0.3848 - acc: 0.8599 - val_loss: 0.3859 - val_acc: 0.8594\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 10s 123ms/step - loss: 0.3839 - acc: 0.8562 - val_loss: 0.3208 - val_acc: 0.8750\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.4106 - acc: 0.8411 - val_loss: 0.3032 - val_acc: 0.9219\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.3718 - acc: 0.8644 - val_loss: 0.1555 - val_acc: 0.9375\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 10s 121ms/step - loss: 0.3413 - acc: 0.8840 - val_loss: 0.3149 - val_acc: 0.8594\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 0.4118 - acc: 0.8449 - val_loss: 0.3230 - val_acc: 0.8750\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.3819 - acc: 0.8707 - val_loss: 0.2003 - val_acc: 0.9375\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.3705 - acc: 0.8660 - val_loss: 0.1469 - val_acc: 0.9219\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 0.3822 - acc: 0.8577 - val_loss: 0.3394 - val_acc: 0.8750\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 10s 120ms/step - loss: 0.3610 - acc: 0.8727 - val_loss: 0.4034 - val_acc: 0.8281\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 10s 124ms/step - loss: 0.3521 - acc: 0.8614 - val_loss: 0.2844 - val_acc: 0.8906\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 10s 119ms/step - loss: 0.3818 - acc: 0.8670 - val_loss: 0.1830 - val_acc: 0.9531\n",
      "INFO:tensorflow:Froze 18 variables.\n",
      "INFO:tensorflow:Converted 18 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os\n",
    "from keras import optimizers\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "train_path='/home/sober/code/jupyter/ftp_code/AndroidTensorflow/tensorflow-for-poets-2/tf_files/flower_photos'\n",
    "val_path='/home/sober/code/jupyter/ftp_code/AndroidTensorflow/tensorflow-for-poets-2/tf_files/flower_photos'\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "def mean(x):\n",
    "    return (x-128.0)\n",
    "\n",
    "input = Input(shape = (150, 150, 3), name = 'input')\n",
    "x = Conv2D(32, (3, 3), activation='relu')(input)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dense(2, activation='sigmoid', name = 'output')(x)\n",
    "x = Dense(5, activation='softmax', name = 'output')(x)\n",
    "model = Model(inputs = input, outputs= x)\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.0005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True, preprocessing_function=mean)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=mean)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1340 // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        shuffle=True,\n",
    "        validation_steps=64 // batch_size)\n",
    "model.save('./weight/flower5tlite_mean.h5')  # always save your weights after training or during training\n",
    "\n",
    "# convert\n",
    "output_names = [node.op.name for node in model.outputs]\n",
    "\n",
    "export_dir = './weight/'\n",
    "sess = K.get_session()\n",
    "# save_graph_to_file(sess,  export_dir + \"flower5.pb\", output_names)\n",
    "keras2tflite(sess, [input], [x], export_dir + \"flower5tlite_mean.tflite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.2",
   "language": "python",
   "name": "3.6.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
